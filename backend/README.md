# FeelMate Emotion-Aware Chatbot - Production MVP

A production-ready, CPU-optimized chatbot that detects emotions and provides empathetic responses. Designed specifically for machines with limited resources (Core i5 CPU, 8GB RAM, HDD storage).

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
cd backend
pip install -r requirements.txt
```

### 2. Start Production Server
```bash
python start_production.py
```

### 3. Start Frontend (in another terminal)
```bash
cd frontend
npm run dev
```

### 4. Open Application
- Frontend: http://localhost:3000
- Backend API: http://localhost:8001
- API Docs: http://localhost:8001/docs

## ğŸ“ Production File Structure

```
backend/
â”œâ”€â”€ chatbot.py              # Core chatbot logic
â”œâ”€â”€ server.py               # FastAPI production server
â”œâ”€â”€ config.py               # Production configuration
â”œâ”€â”€ start_production.py     # Production startup script
â”œâ”€â”€ requirements.txt        # Production dependencies
â”œâ”€â”€ data/                   # Data storage directory
â”œâ”€â”€ logs/                   # Log files directory
â””â”€â”€ README.md              # This file
```

## ğŸ”§ Configuration

Environment variables (optional):
```bash
HOST=0.0.0.0              # Server host
PORT=8001                  # Server port
DEBUG=false                # Debug mode
LOG_LEVEL=INFO            # Logging level
```

## ğŸ“¡ API Endpoints

- **POST** `/chat/invoke` - Main chat endpoint
- **POST** `/api/chat/send-message` - Frontend compatibility
- **GET** `/health` - Health check
- **GET** `/docs` - API documentation

## ğŸ§  Features

- **Emotion Detection**: 7 emotion categories with confidence scores
- **Crisis Detection**: Automatic detection of harmful messages
- **Supportive Responses**: Intelligent, emotion-aware responses
- **Conversation Memory**: Remembers last 5 messages
- **Resource Recommendations**: Crisis and support resources
- **CPU-Optimized**: No GPU required, optimized for Core i5

## ğŸš€ Deployment

### Local Production
```bash
python start_production.py
```

### Manual Server Start
```bash
python server.py
```

### Environment Variables
Create a `.env` file for custom configuration:
```env
HOST=0.0.0.0
PORT=8001
DEBUG=false
LOG_LEVEL=INFO
```

## ğŸ“Š Performance

- **Memory Usage**: ~4-5GB RAM peak
- **Response Time**: 100-500ms per message
- **Model Size**: ~500MB (downloaded once)
- **CPU**: Optimized for Intel Core i5

## ğŸ” Monitoring

- **Health Check**: `/health` endpoint
- **Logs**: Check `logs/` directory
- **API Docs**: Interactive documentation at `/docs`

## ğŸ†˜ Troubleshooting

### Port Already in Use
```bash
# Check what's using port 8001
netstat -ano | findstr :8001

# Kill the process or change port in config.py
```

### Memory Issues
- Close other applications
- Ensure 8GB+ RAM available
- Check Task Manager for memory usage

### Model Loading Issues
- Check internet connection
- Verify sufficient disk space
- Check PyTorch installation

## ğŸ”’ Security

- Input validation with Pydantic
- CORS protection for frontend
- No external API calls
- Local model inference only

## ğŸ“ˆ Scaling

For production scaling:
1. Use reverse proxy (nginx)
2. Implement load balancing
3. Add monitoring (Prometheus/Grafana)
4. Use process manager (PM2/systemd)

---

**Ready for Production! ğŸš€**

Your emotion-aware chatbot is now production-ready and optimized for your hardware constraints.
